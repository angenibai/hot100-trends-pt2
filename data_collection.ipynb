{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_hot100(year):\n",
    "    csv_rows = [['Rank', 'Title', 'Artist(s)', 'Artists Separately']]\n",
    "\n",
    "    url = 'https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_' + str(year)\n",
    "\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    table = soup.find('table', {'class':'wikitable sortable'}).tbody\n",
    "\n",
    "    num = 1\n",
    "    for row in table.find_all('tr'):\n",
    "        # skip empty rows\n",
    "        cells_found = False\n",
    "        if len(row.find_all('td')) == 3:\n",
    "            num_cell, title_cell, artist_cell = row.find_all('td')\n",
    "            cells_found = True\n",
    "        \n",
    "        if not cells_found:\n",
    "            continue\n",
    "\n",
    "        # extract title and artist from their cells\n",
    "        title = title_cell.text.strip()\n",
    "\n",
    "        artist = artist_cell.text.strip() # artists as a string\n",
    "        artists_list = list(map(lambda x: x.getText(), artist_cell.find_all('a'))) # list of artists\n",
    "        artists_separately = \";\".join(artists_list)\n",
    "\n",
    "        # create new row for the csv file\n",
    "        row = [num, title, artist, artists_separately]\n",
    "        csv_rows.append(row)\n",
    "\n",
    "        num += 1\n",
    "        # print(f'Title: {title}, Artist(s): {artist}', artists_list) # ! DEBUG\n",
    "\n",
    "    # append all rows to new csv file\n",
    "    csv_name = 'hot100files/' + str(year) + '.csv'\n",
    "    with open(csv_name, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(csv_rows)\n",
    "\n",
    "    print(f'Collected {year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_YEAR = 1959\n",
    "CUR_YEAR = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for year in range(START_YEAR, CUR_YEAR):\n",
    "    fetch_hot100(year)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hot100-trends-pt2-fNKKwnq2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a14d71ab696e660177272d3de8a02a7f014abd6b6c881ad1bfe4a3436b8521f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
